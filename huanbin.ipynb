{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59']\n",
      "Reading c:\\Users\\clock\\Desktop\\hanzi\\072.fdt\n",
      "Reading 0 ... 881221  =      0.000 ...   881.221 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clock\\AppData\\Local\\Temp\\ipykernel_27808\\1526390704.py:60: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59']\n",
      "Reading c:\\Users\\clock\\Desktop\\hanzi\\031.fdt\n",
      "Reading 0 ... 894021  =      0.000 ...   894.021 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clock\\AppData\\Local\\Temp\\ipykernel_27808\\1526390704.py:60: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59']\n",
      "Reading c:\\Users\\clock\\Desktop\\hanzi\\032.fdt\n",
      "Reading 0 ... 871321  =      0.000 ...   871.321 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clock\\AppData\\Local\\Temp\\ipykernel_27808\\1526390704.py:60: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clock\\AppData\\Local\\Temp\\ipykernel_27808\\1526390704.py:60: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\clock\\Desktop\\hanzi\\007C2.fdt\n",
      "Reading 0 ... 896621  =      0.000 ...   896.621 secs...\n",
      "Used Annotations descriptions: ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59']\n",
      "Reading c:\\Users\\clock\\Desktop\\hanzi\\007C1.fdt\n",
      "Reading 0 ... 881621  =      0.000 ...   881.621 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clock\\AppData\\Local\\Temp\\ipykernel_27808\\1526390704.py:60: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59']\n",
      "Reading c:\\Users\\clock\\Desktop\\hanzi\\008C2.fdt\n",
      "Reading 0 ... 901822  =      0.000 ...   901.822 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clock\\AppData\\Local\\Temp\\ipykernel_27808\\1526390704.py:60: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59']\n",
      "Reading c:\\Users\\clock\\Desktop\\hanzi\\008C1.fdt\n",
      "Reading 0 ... 903022  =      0.000 ...   903.022 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clock\\AppData\\Local\\Temp\\ipykernel_27808\\1526390704.py:60: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\clock\\AppData\\Local\\Temp\\ipykernel_27808\\1526390704.py:60: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  X = epochs.get_data()  # Shape: (n_epochs, n_channels, n_times)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data shape: (7200, 64, 1000), Labels shape: (7200,)\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.1012, Accuracy: 95.85%\n",
      "Epoch [2/50], Loss: 0.0114, Accuracy: 99.69%\n",
      "Epoch [3/50], Loss: 0.0024, Accuracy: 99.98%\n",
      "Epoch [4/50], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [5/50], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [6/50], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [7/50], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [8/50], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [9/50], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [10/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [11/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [12/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [13/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [14/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [15/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [16/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [17/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [18/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [19/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [20/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [21/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [22/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [23/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [24/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [25/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [26/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [27/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [28/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [29/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [30/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [31/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [32/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [33/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [34/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [35/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [36/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [37/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [38/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [39/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [40/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [41/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [42/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [43/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [44/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [45/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [46/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [47/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [48/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [49/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [50/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       562\n",
      "           1       1.00      1.00      1.00       878\n",
      "\n",
      "    accuracy                           1.00      1440\n",
      "   macro avg       1.00      1.00      1.00      1440\n",
      "weighted avg       1.00      1.00      1.00      1440\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[562   0]\n",
      " [  0 878]]\n",
      "Fold 2/5\n",
      "Epoch [1/50], Loss: 0.0860, Accuracy: 96.74%\n",
      "Epoch [2/50], Loss: 0.0078, Accuracy: 99.70%\n",
      "Epoch [3/50], Loss: 0.0100, Accuracy: 99.69%\n",
      "Epoch [4/50], Loss: 0.0059, Accuracy: 99.90%\n",
      "Epoch [5/50], Loss: 0.0029, Accuracy: 99.91%\n",
      "Epoch [6/50], Loss: 0.0145, Accuracy: 99.64%\n",
      "Epoch [7/50], Loss: 0.0046, Accuracy: 99.84%\n",
      "Epoch [8/50], Loss: 0.0028, Accuracy: 99.93%\n",
      "Epoch [9/50], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [10/50], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [11/50], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [12/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [13/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [14/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [15/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [16/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [17/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [18/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [19/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [20/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [21/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [22/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [23/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [24/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [25/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [26/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [27/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [28/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [29/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [30/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [31/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [32/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [33/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [34/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [35/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [36/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [37/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [38/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [39/50], Loss: 0.0000, Accuracy: 100.00%\n",
      "Epoch [40/50], Loss: 0.0000, Accuracy: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 213\u001b[0m\n\u001b[0;32m    210\u001b[0m X, y \u001b[38;5;241m=\u001b[39m process_files(patient_files, normal_files, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed data shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Labels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 213\u001b[0m \u001b[43mk_fold_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 202\u001b[0m, in \u001b[0;36mk_fold_cross_validation\u001b[1;34m(X, y, k, num_epochs)\u001b[0m\n\u001b[0;32m    199\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m    200\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m)\n\u001b[1;32m--> 202\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m evaluate_model(model, test_loader)\n",
      "Cell \u001b[1;32mIn[1], line 144\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m    141\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    142\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 144\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    145\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    146\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def process_files(patient_files, normal_files, tmin, tmax):\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "\n",
    "    patient_X, patient_y = process_set_files(patient_files, tmin, tmax, label=1)\n",
    "    all_X.append(patient_X)\n",
    "    all_y.append(patient_y)\n",
    "\n",
    "    normal_X, normal_y = process_set_files(normal_files, tmin, tmax, label=0)\n",
    "    all_X.append(normal_X)\n",
    "    all_y.append(normal_y)\n",
    "\n",
    "    all_X = np.concatenate(all_X, axis=0)\n",
    "    all_y = np.concatenate(all_y, axis=0)\n",
    "    return all_X, all_y\n",
    "\n",
    "\n",
    "def process_set_files(set_files, tmin, tmax, label):\n",
    "    all_X = []\n",
    "    all_y_group = []\n",
    "    for set_file in set_files:\n",
    "\n",
    "        try:\n",
    "            raw = mne.io.read_raw_eeglab(set_file, preload=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {e}\")\n",
    "            exit()\n",
    "\n",
    "\n",
    "        for ch_name in ['VEOG', 'HEOG', 'Trigger']:\n",
    "            if ch_name in raw.ch_names:\n",
    "                raw.drop_channels([ch_name])\n",
    "\n",
    "        raw.filter(0.5, 80., fir_design='firwin', verbose='ERROR')\n",
    "\n",
    "        events, current_event_id_map = mne.events_from_annotations(raw)\n",
    "        event_id = {f'event_{i}': current_event_id_map.get(str(40 + i)) for i in range(20) if str(40 + i) in current_event_id_map}\n",
    "\n",
    "        epochs = mne.Epochs(raw, events, event_id=event_id, tmin=tmin, tmax=tmax, preload=True, verbose='ERROR', baseline=(0, 0))\n",
    "        X = epochs.get_data() \n",
    "\n",
    "        new_X = []\n",
    "        new_y_group = []\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(3):  \n",
    "                new_X.append(X[i, :, j * int(X.shape[2] / 3): (j + 1) * int(X.shape[2] / 3)])\n",
    "                new_y_group.append(label)  \n",
    "\n",
    "        new_X = np.array(new_X)\n",
    "        new_y_group = np.array(new_y_group)\n",
    "\n",
    "        all_X.append(new_X)\n",
    "        all_y_group.append(new_y_group)\n",
    "\n",
    "\n",
    "    all_X = np.concatenate(all_X, axis=0)\n",
    "    all_y_group = np.concatenate(all_y_group, axis=0)\n",
    "\n",
    "    return all_X, all_y_group\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, num_classes=2, dropout=0.3):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.firstconv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(1, 51), stride=(1, 1), padding=(0, 25), bias=False),\n",
    "            nn.BatchNorm2d(16)\n",
    "        )\n",
    "        self.depthwiseConv = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(64, 1), stride=(1, 1), groups=16, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, 4), stride=(1, 4)),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.separableConv = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=(1, 15), stride=(1, 1), padding=(0, 7), bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, 8), stride=(1, 8)),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.classify = nn.Linear(992, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1) \n",
    "        x = self.firstconv(x)\n",
    "        x = self.depthwiseConv(x)\n",
    "        x = self.separableConv(x)\n",
    "        x = self.flatten(x)\n",
    "        out = self.classify(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "\n",
    "def k_fold_cross_validation(X, y, k=5, num_epochs=50):\n",
    "\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    y = y[indices]\n",
    "    kfold = KFold(n_splits=k, shuffle=False)\n",
    "    fold = 1\n",
    "    for train_idx, test_idx in kfold.split(X):\n",
    "        print(f'Fold {fold}/{k}')\n",
    "        fold += 1\n",
    "\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
    "        X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
    "\n",
    "        train_dataset = EEGDataset(X_train, y_train)\n",
    "        test_dataset = EEGDataset(X_test, y_test)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        model = EEGNet(num_classes=2, dropout=0.3).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "        train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "        evaluate_model(model, test_loader)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    patient_files = ['./061.set', './071.set','./062.set', './072.set','./031.set', './032.set']\n",
    "    normal_files = ['./007C2.set', './007C1.set','./008C2.set', './008C1.set']\n",
    "\n",
    "    X, y = process_files(patient_files, normal_files, 0, 3)\n",
    "    print(f\"Processed data shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "\n",
    "    k_fold_cross_validation(X, y, k=5, num_epochs=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
